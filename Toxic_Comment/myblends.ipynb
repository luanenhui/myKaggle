{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb_submission.csv',\n",
       " 'Logistic_regression_with_words_and_char_n-grams.csv',\n",
       " 'Minimal_LSTM_NB-SVM_baseline_ensemble.csv',\n",
       " 'one_more_blend.csv',\n",
       " 'Pooled_GRU_Fasttext.csv',\n",
       " 'toxic_avenger.csv',\n",
       " 'who09829_gru.csv']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "user_folder = os.path.expanduser('~')\n",
    "data_folder = os.path.join(user_folder, 'E:/git/database/Toxic_Comment/blends')\n",
    "files = os.listdir(data_folder)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = pd.read_csv(os.path.join(data_folder, files[4])) # PL score 0.9829\n",
    "lstm_nb_svm = pd.read_csv(os.path.join(data_folder, files[2])) # 0.9811\n",
    "lr = pd.read_csv(os.path.join(data_folder, files[1])) # 0.9788\n",
    "lgb = pd.read_csv(os.path.join(data_folder, files[0])) # 0.9785\n",
    "blend_p = pd.read_csv(os.path.join(data_folder, files[3])) # 0.9850\n",
    "\n",
    "# ave = pd.read_csv(os.path.join(data_folder, files[5])) # 0.9823\n",
    "\n",
    "\n",
    "weights = pd.Series([0.9829, 0.9811, 0.9788, 0.9785, 0.9850])\n",
    "weights = 1/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling toxic... Please stand by.\n",
      "Scaling severe_toxic... Please stand by.\n",
      "Scaling obscene... Please stand by.\n",
      "Scaling threat... Please stand by.\n",
      "Scaling insult... Please stand by.\n",
      "Scaling identity_hate... Please stand by.\n"
     ]
    }
   ],
   "source": [
    "# Bojan suggests scaling with min-max to make sure that all the submissions have\n",
    "# orderings that can be compared. Since our metric is AUC, this is okay and may\n",
    "# improve performance.\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for label in labels:\n",
    "    print('Scaling {}... Please stand by.'.format(label))\n",
    "    lgb[label] = minmax_scale(lgb[label])\n",
    "    gru[label] = minmax_scale(gru[label])\n",
    "    lr[label] = minmax_scale(lr[label])\n",
    "    lstm_nb_svm[label] = minmax_scale(lstm_nb_svm[label])\n",
    "    blend_p[label] = minmax_scale(blend_p[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "[[1.         0.94926809 0.90236963 0.90111066 0.97783595]\n",
      " [0.94926809 1.         0.95823705 0.94273615 0.98356096]\n",
      " [0.90236963 0.95823705 1.         0.95377901 0.95351634]\n",
      " [0.90111066 0.94273615 0.95377901 1.         0.94253547]\n",
      " [0.97783595 0.98356096 0.95351634 0.94253547 1.        ]]\n",
      "severe_toxic\n",
      "[[1.         0.85339415 0.82051887 0.78884913 0.94681823]\n",
      " [0.85339415 1.         0.88252021 0.8186413  0.9192528 ]\n",
      " [0.82051887 0.88252021 1.         0.86371851 0.89209998]\n",
      " [0.78884913 0.8186413  0.86371851 1.         0.86059469]\n",
      " [0.94681823 0.9192528  0.89209998 0.86059469 1.        ]]\n",
      "obscene\n",
      "[[1.         0.96100403 0.92729218 0.93439385 0.98447173]\n",
      " [0.96100403 1.         0.955631   0.94607069 0.98364744]\n",
      " [0.92729218 0.955631   1.         0.94986687 0.95644366]\n",
      " [0.93439385 0.94607069 0.94986687 1.         0.95585908]\n",
      " [0.98447173 0.98364744 0.95644366 0.95585908 1.        ]]\n",
      "threat\n",
      "[[1.         0.78330735 0.79996174 0.75896158 0.93353892]\n",
      " [0.78330735 1.         0.84338327 0.79585943 0.84106036]\n",
      " [0.79996174 0.84338327 1.         0.83580206 0.85941012]\n",
      " [0.75896158 0.79585943 0.83580206 1.         0.81519356]\n",
      " [0.93353892 0.84106036 0.85941012 0.81519356 1.        ]]\n",
      "insult\n",
      "[[1.         0.93182386 0.88996881 0.89161567 0.97517916]\n",
      " [0.93182386 1.         0.93925792 0.90977553 0.97120108]\n",
      " [0.88996881 0.93925792 1.         0.92276276 0.93577933]\n",
      " [0.89161567 0.90977553 0.92276276 1.         0.92715779]\n",
      " [0.97517916 0.97120108 0.93577933 0.92715779 1.        ]]\n",
      "identity_hate\n",
      "[[1.         0.87086712 0.8130817  0.8159686  0.95980227]\n",
      " [0.87086712 1.         0.88949582 0.82264192 0.93415346]\n",
      " [0.8130817  0.88949582 1.         0.86413218 0.8886656 ]\n",
      " [0.8159686  0.82264192 0.86413218 1.         0.86158425]\n",
      " [0.95980227 0.93415346 0.8886656  0.86158425 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(label)\n",
    "    print(np.corrcoef([gru[label], lstm_nb_svm[label], lr[label], lgb[label], blend_p[label]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "submission = copy.deepcopy(gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [gru, lstm_nb_svm, lr, lgb, blend_p]\n",
    "datasets_rmid = [df.drop('id', axis=1) for df in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [weights[i]*datasets_rmid[i] for i in range(len(datasets))]\n",
    "result = sum(result)/sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:,1:] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('myBlend_scale2_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.992482</td>\n",
       "      <td>0.312776</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.946862</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.992482      0.312776  0.978632  0.041128  0.946862   \n",
       "\n",
       "   identity_hate  \n",
       "0          0.316  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
