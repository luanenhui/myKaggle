{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luan/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/luan/.local/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os,gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.metrics import make_scorer\n",
    "# from mlens.metrics import make_scorer\n",
    "# from mlens.model_selection import Evaluator\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "#import xgboost\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from scipy.sparse import csr_matrix,hstack \n",
    "from sklearn.externals.joblib import dump,load\n",
    "\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_folder = os.path.expanduser(\"~\")\n",
    "data_folder = os.path.join(user_folder, 'E:/git/database/Toxic_Comment')\n",
    "train_df = pd.read_csv(os.path.join(data_folder, 'train_preprocess.csv'), delimiter=',')\n",
    "train_tfidf = load(os.path.join(data_folder, \"train_features_10K.dump\"))\n",
    "test_df_idf = load(os.path.join(data_folder, 'test_features_10K.dump'))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(data_folder, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_scorer = make_scorer(roc_auc_score, greater_is_better=True)\n",
    "pars = {\n",
    "    # \"max_features\": [50, 200],\n",
    "    \"n_estimators\": [20,100],\n",
    "    # \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"min_samples_leaf\": [2, 4]\n",
    "}\n",
    "\n",
    "#ests = [('rf', RandomForestClassifier(random_state=seed))]\n",
    "\n",
    "#evaluator = Evaluator(scorer=roc_scorer, cv=10, random_state=seed)\n",
    "#evaluator.fit(train_tfidf, train_df[\"toxic\"], ests, pars, n_iter=10)\n",
    "#print(\"\\nComparison with different parameter dists:\\n\\n%r\" % evaluator.results)\n",
    "clf = RandomForestClassifier(random_state = seed, n_estimators=50)\n",
    "# roc_score = cross_val_score(clf, train_tfidf, train_df['toxic'], scoring='roc_auc')\n",
    "grid = GridSearchCV(clf, pars, scoring='roc_auc', n_jobs=1, cv=5)\n",
    "grid.fit(train_tfidf, train_df[\"toxic\"],)\n",
    "print(\"Accuracy: {0:.4f}%\".format(grid.best_score_ * 100))\n",
    "gc.collect()\n",
    "# print(clf)\n",
    "# print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=20, verbose=0, warm_start=False)\n",
      "[0.91189561 0.91306193 0.91370311]\n"
     ]
    }
   ],
   "source": [
    "print(clf)\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator is 50 \n",
      " roc_auc_score is [0.95248742 0.9504648  0.95009881]\n"
     ]
    }
   ],
   "source": [
    "print(\"n_estimator is 50 \\nroc_auc_score is %s\" % roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ests = {\n",
    "    'rf': RandomForestClassifier(n_estimators=100, min_samples_leaf=2),\n",
    "    #'lr': LogisticRegression(),\n",
    "    #'svm': SGDClassifier(loss='log')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from copy import deepcopy\n",
    "scorer = make_scorer(roc_auc_score, greater_is_better=True)\n",
    "\n",
    "def predict_one(clf, X_train, y_train, X_test):\n",
    "    clf = clf\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_preds = clf.predict_proba(X_train)\n",
    "    target_preds = clf.predict_proba(X_test)\n",
    "    return train_preds, target_preds\n",
    "    \n",
    "def predict_all(clf, X_train, y_train, X_test, labels):\n",
    "    train_preds_matrix = pd.DataFrame(y_train)\n",
    "    test_preds_matrix = np.zeros((X_test.shape[0], len(labels)))\n",
    "    test_preds_matrix = pd.DataFrame(test_preds_matrix); test_preds_matrix.columns = labels\n",
    "    \n",
    "    idx = 0\n",
    "    for label in labels:\n",
    "        print(\"Fit %s\" % label)\n",
    "        train_target = y_train[label].values\n",
    "        first,second = predict_one(clf, X_train, train_target, X_test)\n",
    "        \n",
    "        train_preds_matrix.iloc[:,idx] = first[:,1]\n",
    "        test_preds_matrix.iloc[:,idx] = second[:,1]\n",
    "        idx += 1\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    return train_preds_matrix, test_preds_matrix\n",
    "\n",
    "#y_train = train_df[class_names].values\n",
    "#train_preds, test_preds = predict_all(clf=LogisticRegression(), X_train=train_tfidf, y_train=train_df[class_names], X_test=test_df_idf,labels = class_names)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rf Model...\n",
      "Fit toxic\n",
      "Fit severe_toxic\n",
      "Fit obscene\n",
      "Fit threat\n",
      "Fit insult\n",
      "Fit identity_hate\n"
     ]
    }
   ],
   "source": [
    "for key in ests.keys():\n",
    "    print(\"Using %s Model...\" % key)\n",
    "    clf = ests[key]\n",
    "    train_preds, test_preds = predict_all(clf=clf, X_train=train_tfidf, y_train=train_df[class_names], X_test=test_df_idf,labels = class_names)\n",
    "    submission[class_names] = test_preds\n",
    "    \n",
    "    train_preds.to_csv(os.path.join(data_folder, '%s_train_preds.csv' % key), index=False)\n",
    "    submission.to_csv(os.path.join(data_folder, '%s_submission.csv' % key), index=False)\n",
    "    \n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit toxic\n",
      "[10]\ttraining's auc: 0.924316\tvalid_1's auc: 0.91445\n",
      "[20]\ttraining's auc: 0.950664\tvalid_1's auc: 0.939425\n",
      "[30]\ttraining's auc: 0.964818\tvalid_1's auc: 0.951219\n",
      "[40]\ttraining's auc: 0.972761\tvalid_1's auc: 0.958237\n",
      "[50]\ttraining's auc: 0.977387\tvalid_1's auc: 0.962321\n",
      "[60]\ttraining's auc: 0.980612\tvalid_1's auc: 0.963214\n",
      "[70]\ttraining's auc: 0.983383\tvalid_1's auc: 0.965316\n",
      "[80]\ttraining's auc: 0.985493\tvalid_1's auc: 0.9661\n",
      "[90]\ttraining's auc: 0.98727\tvalid_1's auc: 0.965848\n",
      "[100]\ttraining's auc: 0.988661\tvalid_1's auc: 0.965916\n",
      "[110]\ttraining's auc: 0.989888\tvalid_1's auc: 0.965769\n",
      "[120]\ttraining's auc: 0.990915\tvalid_1's auc: 0.966116\n",
      "[130]\ttraining's auc: 0.991823\tvalid_1's auc: 0.966104\n",
      "[140]\ttraining's auc: 0.992629\tvalid_1's auc: 0.966358\n",
      "predict test toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luan/.local/lib/python3.5/site-packages/lightgbm/basic.py:447: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict train toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luan/.local/lib/python3.5/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit severe_toxic\n",
      "[10]\ttraining's auc: 0.965592\tvalid_1's auc: 0.920757\n",
      "[20]\ttraining's auc: 0.983912\tvalid_1's auc: 0.982633\n",
      "[30]\ttraining's auc: 0.994046\tvalid_1's auc: 0.983981\n",
      "[40]\ttraining's auc: 0.996289\tvalid_1's auc: 0.984186\n",
      "[50]\ttraining's auc: 0.997551\tvalid_1's auc: 0.984379\n",
      "predict test severe_toxic\n",
      "predict train severe_toxic\n",
      "Fit obscene\n",
      "[10]\ttraining's auc: 0.979214\tvalid_1's auc: 0.979128\n",
      "[20]\ttraining's auc: 0.987461\tvalid_1's auc: 0.989109\n",
      "[30]\ttraining's auc: 0.991848\tvalid_1's auc: 0.990542\n",
      "[40]\ttraining's auc: 0.994167\tvalid_1's auc: 0.991946\n",
      "[50]\ttraining's auc: 0.995642\tvalid_1's auc: 0.993556\n",
      "[60]\ttraining's auc: 0.996645\tvalid_1's auc: 0.993432\n",
      "[70]\ttraining's auc: 0.997276\tvalid_1's auc: 0.99319\n",
      "[80]\ttraining's auc: 0.997782\tvalid_1's auc: 0.993031\n",
      "predict test obscene\n",
      "predict train obscene\n",
      "Fit threat\n",
      "[10]\ttraining's auc: 0.939612\tvalid_1's auc: 0.914157\n",
      "[20]\ttraining's auc: 0.975657\tvalid_1's auc: 0.964327\n",
      "[30]\ttraining's auc: 0.995004\tvalid_1's auc: 0.982171\n",
      "[40]\ttraining's auc: 0.998306\tvalid_1's auc: 0.989785\n",
      "[50]\ttraining's auc: 0.999574\tvalid_1's auc: 0.988931\n",
      "[60]\ttraining's auc: 0.999867\tvalid_1's auc: 0.988793\n",
      "[70]\ttraining's auc: 0.999948\tvalid_1's auc: 0.98856\n",
      "[80]\ttraining's auc: 0.999978\tvalid_1's auc: 0.987454\n",
      "predict test threat\n",
      "predict train threat\n",
      "Fit insult\n",
      "[10]\ttraining's auc: 0.954531\tvalid_1's auc: 0.951228\n",
      "[20]\ttraining's auc: 0.970126\tvalid_1's auc: 0.960068\n",
      "[30]\ttraining's auc: 0.978937\tvalid_1's auc: 0.967224\n",
      "[40]\ttraining's auc: 0.984002\tvalid_1's auc: 0.972346\n",
      "[50]\ttraining's auc: 0.987294\tvalid_1's auc: 0.975411\n",
      "[60]\ttraining's auc: 0.989592\tvalid_1's auc: 0.975731\n",
      "[70]\ttraining's auc: 0.991148\tvalid_1's auc: 0.976238\n",
      "predict test insult\n",
      "predict train insult\n",
      "Fit identity_hate\n",
      "[10]\ttraining's auc: 0.940812\tvalid_1's auc: 0.894627\n",
      "[20]\ttraining's auc: 0.975699\tvalid_1's auc: 0.947032\n",
      "[30]\ttraining's auc: 0.991141\tvalid_1's auc: 0.971412\n",
      "[40]\ttraining's auc: 0.995653\tvalid_1's auc: 0.976887\n",
      "[50]\ttraining's auc: 0.997679\tvalid_1's auc: 0.975404\n",
      "[60]\ttraining's auc: 0.998705\tvalid_1's auc: 0.976204\n",
      "[70]\ttraining's auc: 0.999261\tvalid_1's auc: 0.977929\n",
      "[80]\ttraining's auc: 0.999552\tvalid_1's auc: 0.978073\n",
      "predict test identity_hate\n",
      "predict train identity_hate\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "train_preds = train_df[class_names]\n",
    "for class_name in class_names:\n",
    "    print(\"Fit %s\" % class_name)\n",
    "    train_target = train_df[class_name]\n",
    "    train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_tfidf, train_target, test_size=0.05, random_state=144)\n",
    "    d_train = lgb.Dataset(train_sparse_matrix, label=y_train)\n",
    "    d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    \n",
    "    del train_target, train_sparse_matrix, valid_sparse_matrix, y_train, y_valid \n",
    "    gc.collect()\n",
    "    \n",
    "    params = {'learning_rate': 0.2,\n",
    "          'application': 'binary',\n",
    "          'num_leaves': 31,\n",
    "          'verbosity': -1,\n",
    "          'metric': 'auc',\n",
    "          'data_random_seed': 2,\n",
    "          'bagging_fraction': 0.8,\n",
    "          'feature_fraction': 0.6,\n",
    "          'nthread': 4,\n",
    "          'lambda_l1': 1,\n",
    "          'lambda_l2': 1}\n",
    "    rounds_lookup = {'toxic': 80,   # >80 not inreae valid auc\n",
    "                 'severe_toxic': 50,  # can increase lookup from 50\n",
    "                 'obscene': 80,  # >50 not increase valid auc\n",
    "                 'threat': 80,   # >40 not increase valid auc\n",
    "                 'insult': 70,   # can increase lookup from 70\n",
    "                 'identity_hate': 80} # >30 not increase valid auc\n",
    "    model = lgb.train(params, train_set=d_train, num_boost_round=rounds_lookup[class_name], valid_sets=watchlist,verbose_eval=10)\n",
    "    \n",
    "    print(\"predict test %s\" % class_name)\n",
    "    submission[class_name] = model.predict(test_df_idf)\n",
    "    print(\"predict train %s\" % class_name)\n",
    "    train_preds[class_name] = model.predict(train_tfidf)\n",
    "    \n",
    "    del d_train, d_valid, watchlist, model\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.to_csv(os.path.join(data_folder, 'lgb_train_preds.csv'), index=False)\n",
    "submission.to_csv(os.path.join(data_folder, 'lgb_submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98599063, 0.9938711 , 0.99548419, 0.99668764, 0.9893959 ,\n",
       "       0.9937097 ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scoring(y_true, y_score, labels):\n",
    "    score = np.zeros((len(labels),))\n",
    "    idx = 0\n",
    "    for label in labels:\n",
    "        score[idx] = roc_auc_score(y_true[label], y_score[label])\n",
    "        idx += 1\n",
    "    score = score.mean()\n",
    "    return score\n",
    "        \n",
    "\n",
    "scoring(train_df, train_preds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LogisticRegression调参](http://blog.csdn.net/sun_shengyun/article/details/53811483)\n",
    "1. penalty惩罚项，[l2,l1]\n",
    "2. solver优化方法, L2正则化可选四种算法{‘newton-cg','lbfgs','liblinear','sag'}, L1正则化只能选’liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = ([('vectorization', CountVectorizer()),\n",
    "               ('classifier', LogisticRegressionCV())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores = cross_val_score(lr_pipeline, X_train, y_train, scoring = 'roc_auc_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 持久化\n",
    "　　externals.joblib包提供了dump和load方法来持久化和加载内存数据：\n",
    "> #持久化数据  \n",
    "#第一个参数为内存中的对象  \n",
    "#第二个参数为保存在文件系统中的名称  \n",
    "#第三个参数为压缩级别，0为不压缩，3为合适的压缩级别  \n",
    "dump(grid_search, 'grid_search.dmp', compress=3)  \n",
    "#从文件系统中加载数据到内存中  \n",
    "grid_search = load('grid_search.dmp')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型 http://blog.csdn.net/u012102306/article/details/52299589\n",
    "from sklearn.externals.joblib import dump,load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
