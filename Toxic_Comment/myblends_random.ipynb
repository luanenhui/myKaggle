{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb_submission.csv',\n",
       " 'Logistic_regression_with_words_and_char_n-grams.csv',\n",
       " 'Minimal_LSTM_NB-SVM_baseline_ensemble.csv',\n",
       " 'one_more_blend.csv',\n",
       " 'Pooled_GRU_Fasttext.csv',\n",
       " 'toxic_avenger.csv',\n",
       " 'who09829_gru.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "user_folder = os.path.expanduser('~')\n",
    "data_folder = os.path.join(user_folder, 'E:/git/database/Toxic_Comment/blends')\n",
    "files = os.listdir(data_folder)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = pd.read_csv(os.path.join(data_folder, files[4])) # PL score 0.9829\n",
    "lstm_nb_svm = pd.read_csv(os.path.join(data_folder, files[2])) # 0.9811\n",
    "lr = pd.read_csv(os.path.join(data_folder, files[1])) # 0.9788\n",
    "lgb = pd.read_csv(os.path.join(data_folder, files[0])) # 0.9785\n",
    "blend_p = pd.read_csv(os.path.join(data_folder, files[3])) # 0.9850\n",
    "\n",
    "# ave = pd.read_csv(os.path.join(data_folder, files[5])) # 0.9823\n",
    "\n",
    "\n",
    "weights = pd.Series([0.9829, 0.9811, 0.9788, 0.9785, 0.9850])\n",
    "weights = 1/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling toxic... Please stand by.\n",
      "Scaling severe_toxic... Please stand by.\n",
      "Scaling obscene... Please stand by.\n",
      "Scaling threat... Please stand by.\n",
      "Scaling insult... Please stand by.\n",
      "Scaling identity_hate... Please stand by.\n"
     ]
    }
   ],
   "source": [
    "# Bojan suggests scaling with min-max to make sure that all the submissions have\n",
    "# orderings that can be compared. Since our metric is AUC, this is okay and may\n",
    "# improve performance.\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for label in labels:\n",
    "    print('Scaling {}... Please stand by.'.format(label))\n",
    "    lgb[label] = minmax_scale(lgb[label])\n",
    "    gru[label] = minmax_scale(gru[label])\n",
    "    lr[label] = minmax_scale(lr[label])\n",
    "    lstm_nb_svm[label] = minmax_scale(lstm_nb_svm[label])\n",
    "    blend_p[label] = minmax_scale(blend_p[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for label in labels:\n",
    "#    print(label)\n",
    "#    print(np.corrcoef([gru[label], lstm_nb_svm[label], lr[label], lgb[label], blend_p[label]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "submission = copy.deepcopy(gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [gru, lstm_nb_svm, lr, lgb, blend_p]\n",
    "datasets_rmid = [df.drop('id', axis=1) for df in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = gru.drop('id', axis=1)\n",
    "init = copy.deepcopy(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "for i in range(100):\n",
    "    \n",
    "    index = np.random.choice(range(5), size=2, replace=False)\n",
    "    init = init + 0.5*datasets_rmid[index[0]] + 0.5*datasets_rmid[index[1]]\n",
    "\n",
    "average = (init - average)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994860</td>\n",
       "      <td>0.360438</td>\n",
       "      <td>0.984070</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>0.948635</td>\n",
       "      <td>0.305460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic  severe_toxic   obscene    threat    insult  identity_hate\n",
       "0  0.994860      0.360438  0.984070  0.048041  0.948635       0.305460\n",
       "1  0.002818      0.000959  0.001393  0.000086  0.001850       0.000599\n",
       "2  0.007591      0.001184  0.004118  0.000196  0.002698       0.000611"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:,1:] = average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('myBlend_random_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.99486</td>\n",
       "      <td>0.360438</td>\n",
       "      <td>0.98407</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>0.948635</td>\n",
       "      <td>0.30546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    toxic  severe_toxic  obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.99486      0.360438  0.98407  0.048041  0.948635   \n",
       "\n",
       "   identity_hate  \n",
       "0        0.30546  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
